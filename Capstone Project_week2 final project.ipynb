{"cells": [{"metadata": {"collapsed": true}, "cell_type": "markdown", "source": " This notebook will be mainly used for the capstone project\n "}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd\nimport numpy as np", "execution_count": 1, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "print(\"Hello Capstone Project Course!\")", "execution_count": 2, "outputs": [{"output_type": "stream", "text": "Hello Capstone Project Course!\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "<H3> Introduction | Business Undertanding</H3>"}, {"metadata": {}, "cell_type": "markdown", "source": "The government is going to prevent avoidable car accidents by employing methods that alert drivers, health system, and police to remind them to be more careful in critical situations."}, {"metadata": {}, "cell_type": "markdown", "source": "In most cases, not paying enough attention during driving, abusing drugs and alcohol or driving at very high speed are the main causes of occurring accidents that can be prevented by enacting harsher regulations. Besides the aforementioned reasons, weather, visibility, or road conditions are the major uncontrollable factors that can be prevented by revealing hidden patterns in the data and announcing warning to the local government, police and drivers on the targeted roads."}, {"metadata": {}, "cell_type": "markdown", "source": "The target audience of the project is local Seattle government, police, rescue groups, and last but not least, car insurance institutes. The model and its results are going to provide some advice for the target audience to make insightful decisions for reducing the number of accidents and injuries for the city."}, {"metadata": {}, "cell_type": "markdown", "source": "<H3> Data Understanding</H3>"}, {"metadata": {}, "cell_type": "markdown", "source": "The data was collected by the Seattle Police Department and Accident Traffic Records Department from 2006 to present."}, {"metadata": {}, "cell_type": "markdown", "source": "The data consists of 37 independent variables and 194,673 rows. The dependent variable, \u201cSEVERITYCODE\u201d, contains numbers that correspond to different levels of severity caused by an accident from 1 to 2."}, {"metadata": {}, "cell_type": "markdown", "source": "Severity codes are as follows:"}, {"metadata": {}, "cell_type": "markdown", "source": "1: Property Damage Only Collision"}, {"metadata": {}, "cell_type": "markdown", "source": "2: Injury Collision"}, {"metadata": {}, "cell_type": "markdown", "source": "Furthermore, because of the existence of null values in some records, the data needs to be preprocessed before any further processing."}, {"metadata": {}, "cell_type": "markdown", "source": "<h3>Data Preprocessing</h3>"}, {"metadata": {}, "cell_type": "markdown", "source": "The dataset in the original form is not ready for data analysis. In order to prepare the data, first, we need to drop the non-relevant columns. In addition, most of the features are of object data types that need to be converted into numerical data types."}, {"metadata": {}, "cell_type": "markdown", "source": "After analyzing the data set, I have decided to focus on only four features, severity, weather conditions, road conditions, and light conditions, among others.\nTo get a good understanding of the dataset, I have checked different values in the features. The results show, the target feature is imbalance, so we use a simple statistical technique to balance it."}, {"metadata": {}, "cell_type": "code", "source": "links={'Collisions':'https://s3.us.cloud-object-storage.appdomain.cloud/cf-courses-data/CognitiveClass/DP0701EN/version-2/Data-Collisions.csv'}", "execution_count": 3, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "pre_df=pd.read_csv(links[\"Collisions\"])", "execution_count": 4, "outputs": [{"output_type": "stream", "text": "/opt/conda/envs/Python36/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3020: DtypeWarning: Columns (33) have mixed types. Specify dtype option on import or set low_memory=False.\n  interactivity=interactivity, compiler=compiler, result=result)\n", "name": "stderr"}]}, {"metadata": {}, "cell_type": "code", "source": "pre_df[\"SEVERITYCODE\"].value_counts()", "execution_count": 5, "outputs": [{"output_type": "execute_result", "execution_count": 5, "data": {"text/plain": "1    136485\n2     58188\nName: SEVERITYCODE, dtype: int64"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "As you can see, the number of rows in class 1 is almost three times bigger than the number of rows in class 2. It is possible to solve the issue by downsampling the class 1."}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.utils import resample\n\npre_df_maj = pre_df[pre_df.SEVERITYCODE==1]\npre_df_min = pre_df[pre_df.SEVERITYCODE==2]\n\npre_df_maj_dsample = resample(pre_df_maj, replace=False, n_samples=58188, random_state=123)\n\nbalanced_df = pd.concat([pre_df_maj_dsample,pre_df_min])\n\nbalanced_df.SEVERITYCODE.value_counts()", "execution_count": 6, "outputs": [{"output_type": "execute_result", "execution_count": 6, "data": {"text/plain": "2    58188\n1    58188\nName: SEVERITYCODE, dtype: int64"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "<h3>Methodology</h3>"}, {"metadata": {}, "cell_type": "markdown", "source": "For implementing the solution, I have used Github as a repository and running Jupyter Notebook to preprocess data and build Machine Learning models. Regarding coding, I have used Python and its popular packages such as Pandas, NumPy and Sklearn"}, {"metadata": {}, "cell_type": "markdown", "source": "Once I have load data into Pandas Dataframe, used \u2018dtypes\u2019 attribute to check the feature names and their data types. Then I have selected the most important features to predict the severity of accidents in Seattle. Among all the features, the following features have the most influence in the accuracy of the predictions:"}, {"metadata": {}, "cell_type": "markdown", "source": "\u201cWEATHER\u201d,\n\u201cROADCOND\u201d,\n\u201cLIGHTCOND\u201d"}, {"metadata": {}, "cell_type": "markdown", "source": "Also, as I mentioned earlier, \u201cSEVERITYCODE\u201d is the target variable."}, {"metadata": {}, "cell_type": "markdown", "source": "I have run a value count on road (\u2018ROADCOND\u2019) and weather condition (\u2018WEATHER\u2019) to get ideas of the different road and weather conditions. I also have run a value count on light condition (\u2019LIGHTCOND\u2019), to see the breakdowns of accidents occurring during the different light conditions. The results can be seen below:"}, {"metadata": {}, "cell_type": "code", "source": "pre_df[\"WEATHER\"].value_counts()", "execution_count": 7, "outputs": [{"output_type": "execute_result", "execution_count": 7, "data": {"text/plain": "Clear                       111135\nRaining                      33145\nOvercast                     27714\nUnknown                      15091\nSnowing                        907\nOther                          832\nFog/Smog/Smoke                 569\nSleet/Hail/Freezing Rain       113\nBlowing Sand/Dirt               56\nSevere Crosswind                25\nPartly Cloudy                    5\nName: WEATHER, dtype: int64"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "pre_df[\"ROADCOND\"].value_counts()", "execution_count": 8, "outputs": [{"output_type": "execute_result", "execution_count": 8, "data": {"text/plain": "Dry               124510\nWet                47474\nUnknown            15078\nIce                 1209\nSnow/Slush          1004\nOther                132\nStanding Water       115\nSand/Mud/Dirt         75\nOil                   64\nName: ROADCOND, dtype: int64"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "pre_df[\"LIGHTCOND\"].value_counts()", "execution_count": 9, "outputs": [{"output_type": "execute_result", "execution_count": 9, "data": {"text/plain": "Daylight                    116137\nDark - Street Lights On      48507\nUnknown                      13473\nDusk                          5902\nDawn                          2502\nDark - No Street Lights       1537\nDark - Street Lights Off      1199\nOther                          235\nDark - Unknown Lighting         11\nName: LIGHTCOND, dtype: int64"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "After balancing SEVERITYCODE feature, and standardizing the input feature, the data has been ready for building machine learning models.\nI have employed three machine learning models:"}, {"metadata": {}, "cell_type": "markdown", "source": "K Nearest Neighbour (KNN), \nDecision Tree, \nLinear Regression"}, {"metadata": {}, "cell_type": "markdown", "source": "After importing necessary packages and splitting preprocessed data into test and train sets, for each machine learning model, I have built and evaluated the model and shown the results as follow:"}, {"metadata": {}, "cell_type": "code", "source": "Feature = pre_df[['WEATHER','ROADCOND','LIGHTCOND']]\n\nX = Feature\n\nfrom sklearn import preprocessing\nX= preprocessing.StandardScaler().fit(X).transform(X)\nX[0:5]\n\ny = pre_df['SEVERITYCODE'].values\ny[0:5]\n\nX_train, y_train=X,y", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<H3>KNN<H3>"}, {"metadata": {}, "cell_type": "markdown", "source": "Knearest neighbors"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.neighbors import KNeighborsClassifier\nk=17\nknn=KNeighborsClassifier(n_neighbors=k).fit(X_train,y_train)\n\nknn_y_pred=knn.predict(X_test)\nknn_y_pred[0:5]", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "KNN Evaluation"}, {"metadata": {}, "cell_type": "code", "source": "jaccard_score(y_test, knn_y_pred)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "f1_score(y_test, knn_y_pred,average=\"macro\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<H3>Decision Tree<H3>"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.tree import DecisionTreeClassifier\ndt = DecisionTreeClassifier(criterion=\"entropy\", max_depth=7)\ndt.fit(X_train,y_train)\ndt_y_pred = dt.predict(X_test)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Decision tree evaluation"}, {"metadata": {}, "cell_type": "code", "source": "jaccard_score(y_test, dt_y_pred)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "f1_score(y_test, dt_y_pred,average=\"macro\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<H3>Linear Rgression</H3>"}, {"metadata": {}, "cell_type": "code", "source": "from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nLR = LogisticRegression(C=6, solver='liblinear').fit(X_train,y_train)\n\nLR_y_pred = LR.predict(X_test)\n\nLR_y_prob = LR.predict_proba(X_test)\n\nlog loss(y_test, LR_y_prob)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "Linear Regression Evaluation"}, {"metadata": {}, "cell_type": "code", "source": "jaccard_score(y_test, LR_y_pred)", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "f1_score(y_test, LR_y_pred,average=\"macro\")", "execution_count": null, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "<H3>Evaluation</H3>"}, {"metadata": {}, "cell_type": "markdown", "source": "Based on teh above result KNN is the best model to predict the car acident"}, {"metadata": {}, "cell_type": "code", "source": "", "execution_count": null, "outputs": []}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.9", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}